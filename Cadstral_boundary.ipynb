{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9QGGFdeOiX2",
        "outputId": "5b70091e-2668-46b5-8571-5ce3a4e0cf1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m546.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "Successfully installed keras-3.9.2\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.11.0.86\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade keras\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "80zlgq-nAY0_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import filters\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet101, ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i741JSWTRVVJ",
        "outputId": "bf200d99-b505-4a26-c932-e6ffd9efaf17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvjnrc530wSu"
      },
      "outputs": [],
      "source": [
        "# Define the folder path for your data\n",
        "image_dir = '/content/drive/My Drive/Output/images'  # Update this path\n",
        "label_dir = '/content/drive/My Drive/Output/labels'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW4Il0qnBNLG"
      },
      "outputs": [],
      "source": [
        "# 1. Load the images and labels from the directory\n",
        "def load_images_and_labels(image_dir, label_dir):\n",
        "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "    label_files = [f for f in os.listdir(label_dir) if f.endswith('.png')]\n",
        "\n",
        "    image_files.sort()\n",
        "    label_files.sort()\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for image_file, label_file in tqdm(zip(image_files, label_files), total=len(image_files), desc=\"Loading images and labels\"):\n",
        "        img_path = os.path.join(image_dir, image_file)\n",
        "        label_path = os.path.join(label_dir, label_file)\n",
        "\n",
        "        # Read image and label\n",
        "        img = cv2.imread(img_path)\n",
        "        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Resize image and label to 256x256\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "        label = cv2.resize(label, (256, 256))\n",
        "\n",
        "        # Normalize image (0-1)\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "\n",
        "        # Convert label to binary (0 or 1)\n",
        "        label = (label > 127).astype(np.uint8)\n",
        "\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f5ac09fDlnj"
      },
      "outputs": [],
      "source": [
        "# U-Net model with ResNet50 backbone\n",
        "def unet_resnet50(input_size=(256, 256, 3)):\n",
        "    # Load the ResNet50 backbone without the top layer\n",
        "    base_model = ResNet101(weights='imagenet', include_top=False, input_shape=input_size)\n",
        "\n",
        "    # Encoder: ResNet50 layers\n",
        "    encoder_output = base_model.output\n",
        "    encoder_output = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "\n",
        "    # Decoder: Upsampling layers\n",
        "    up1 = layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(encoder_output)\n",
        "    up1 = layers.Concatenate()([up1, base_model.get_layer('conv4_block6_out').output])\n",
        "\n",
        "    up2 = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(up1)\n",
        "    up2 = layers.Concatenate()([up2, base_model.get_layer('conv3_block4_out').output])\n",
        "\n",
        "    up3 = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(up2)\n",
        "    up3 = layers.Concatenate()([up3, base_model.get_layer('conv2_block3_out').output])\n",
        "\n",
        "    up4 = layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(up3)\n",
        "    up4 = layers.Concatenate()([up4, base_model.get_layer('conv1_relu').output])\n",
        "\n",
        "    # Final Output Layer: 1 channel for binary classification (background or object)\n",
        "    output = layers.Conv2D(1, (1, 1), activation='sigmoid')(up4)\n",
        "\n",
        "    # Upsample output to match the input size (256x256)\n",
        "    output = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(output)\n",
        "\n",
        "    # Build the model\n",
        "    model = models.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR3ZlElf0a7_"
      },
      "outputs": [],
      "source": [
        "# 3. Split the data into training and testing sets\n",
        "def split_data(images, labels, test_size=0.2):\n",
        "    # Use train_test_split to split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "    print(f\"Training data shape: {X_train.shape}\")\n",
        "    print(f\"Testing data shape: {X_test.shape}\")\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbMPvc610a5X",
        "outputId": "6dfa7d4d-237b-40ff-9b23-abf985972f3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading images and labels: 100%|██████████| 6226/6226 [36:42<00:00,  2.83it/s]\n"
          ]
        }
      ],
      "source": [
        "images, labels = load_images_and_labels(image_dir, label_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ0CHWn88_JS"
      },
      "outputs": [],
      "source": [
        "# 5. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = split_data(images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKNGBbC0-KLo"
      },
      "outputs": [],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vyw1HwGH-KFq"
      },
      "outputs": [],
      "source": [
        "y_train[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0wmUY7c-KCv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FoaKigz-KAQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO_wu1yw9JdC"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, X_train.dtype)\n",
        "print(X_test.shape,X_test.dtype)\n",
        "print(y_train.shape,y_train.dtype)\n",
        "print(y_test.shape,y_test.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IG__ATEP9JaZ"
      },
      "outputs": [],
      "source": [
        "y_train = np.expand_dims(y_train, axis=-1)\n",
        "y_test = np.expand_dims(y_test, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9feuq1-G9JX5"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jhVBTbkENaW"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBBsUs7OEcWN"
      },
      "outputs": [],
      "source": [
        "y_test[20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JhEz_Z53USV"
      },
      "outputs": [],
      "source": [
        "# Plot the actual image (X_test[0])\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(y_test[0])  # Display the original image\n",
        "plt.title(\"Actual Image (X_test[0])\")\n",
        "plt.axis('off')  # Hide the axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADjgR-0e9JVJ"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape, X_train.dtype)\n",
        "print(X_test.shape,X_test.dtype)\n",
        "print(y_train.shape,y_train.dtype)\n",
        "print(y_test.shape,y_test.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaN51abCspMW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1e-6  # Avoid division by zero\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1W-mdvc0azv"
      },
      "outputs": [],
      "source": [
        "# model = unet_model(input_shape=(256, 256, 3))\n",
        "# model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "#               loss=BinaryCrossentropy(),\n",
        "#               # metrics=[MeanIoU(num_classes=2)]\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# Create the U-Net model\n",
        "model = unet_resnet101(input_size=(256, 256, 3))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss=dice_loss, metrics=[MeanIoU(num_classes=2)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxZ57_PsElEr"
      },
      "outputs": [],
      "source": [
        "# ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Fit the generator on your data\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHgQ5zNZElB_"
      },
      "outputs": [],
      "source": [
        "# # Reshaping the y_train to (256, 256, 1)\n",
        "# y_train = y_train[..., np.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0OM-Sa6Ek9C"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    ModelCheckpoint('unet_resnet50_best_model.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=16),\n",
        "                    epochs=10,\n",
        "                    steps_per_epoch=5,\n",
        "                    callbacks=callbacks,validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zgN1_26Hafg"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "eVp1aSVxHkS-",
        "outputId": "a48071c0-0e15-4ceb-b849-6b7642fb193c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0e147a3957b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z6pK5ZeHnTt"
      },
      "outputs": [],
      "source": [
        "print(predictions[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dodhmpgK7OM"
      },
      "outputs": [],
      "source": [
        "print(X_test[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSFBTqbCLHYd"
      },
      "outputs": [],
      "source": [
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhJsK1HUJUo9"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZmwbliEJM1m"
      },
      "outputs": [],
      "source": [
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eezSteFoH9tl"
      },
      "outputs": [],
      "source": [
        "# Plot the actual image (X_test[0])\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(predictions[0])  # Display the original image\n",
        "plt.title(\"Actual Image (X_test[0])\")\n",
        "plt.axis('off')  # Hide the axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzpS9LkCJJt1"
      },
      "outputs": [],
      "source": [
        "# Plot the actual image (X_test[0])\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(y_test[20])  # Display the original image\n",
        "plt.title(\"Actual Image (X_test[0])\")\n",
        "plt.axis('off')  # Hide the axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fJWlkvBlsP0"
      },
      "outputs": [],
      "source": [
        "y_test[20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkvLDR2hmoMU"
      },
      "outputs": [],
      "source": [
        "predicted_mask = (predictions[10] > 0.5).astype(np.uint8)\n",
        "predicted_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bM_IElIuoLKt"
      },
      "outputs": [],
      "source": [
        "# Plot the actual image (X_test[0])\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(predicted_mask)  # Display the original image\n",
        "plt.title(\"Actual Image (X_test[0])\")\n",
        "plt.axis('off')  # Hide the axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSR2145QkOjd"
      },
      "outputs": [],
      "source": [
        "pred=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViiEbmKXpHbY"
      },
      "outputs": [],
      "source": [
        "pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbt6glYEpX9A"
      },
      "outputs": [],
      "source": [
        "y_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj9Qb0KjpkXf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "thresholded_predictions = predicted_mask\n",
        "actual_array = y_test[10]\n",
        "# Flatten the arrays to compute IoU (Intersection over Union)\n",
        "flat_predictions = thresholded_predictions.flatten()\n",
        "flat_labels = actual_array.flatten()\n",
        "\n",
        "iou = jaccard_score(flat_labels, flat_predictions)\n",
        "print(f\"Intersection over Union (IoU): {iou}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdCZQaU6rSa2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}